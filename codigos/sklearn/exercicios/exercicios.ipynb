{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "mG-LWYiYLX3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSC1RCWoK6b7"
      },
      "outputs": [],
      "source": [
        "#exercicio de treino\n",
        "create_data = {\n",
        "    'TerrenoM2': [50, 100, 140, np.nan, 200, 250, 300],\n",
        "    'quartos': [2, 3, 4, 2, np.nan, 5, 6],\n",
        "    'localização': ['Suldeste', 'Norte', 'Norte', 'Noroeste', 'Sul', 'Suldeste', 'Sul'],\n",
        "    'preço': [100.000, 140.000, 200.000, 175.000, 350.000, 400.000, 450.000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(create_data)\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "df['TerrenoM2'] = imputer.fit_transform(df[['TerrenoM2']])\n",
        "df['quartos'] = imputer.fit_transform(df[['quartos']])\n",
        "\n",
        "column_transformer = ColumnTransformer(\n",
        "    [('enconder', OneHotEncoder(), ['localização'])], # Changed from list to tuple here\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "x = column_transformer.fit_transform(df.drop('preço', axis=1))\n",
        "\n",
        "\n",
        "y = df['preço']\n",
        "\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(x, y)\n",
        "\n",
        "data_to_predict = pd.DataFrame({\n",
        "    'TerrenoM2': [200, 150, 100, 150, 100, 150, 240],\n",
        "    'quartos': [4, 3, 2, 3, 4, 2, 5],\n",
        "    'localização': ['Sul', 'Noroeste', 'Norte', 'Noroeste', 'Sul', 'Norte', 'Sul']\n",
        "})\n",
        "\n",
        "transformed_data = column_transformer.transform(data_to_predict)\n",
        "linear_predict = linear_regression.predict(transformed_data)\n",
        "\n",
        "print(linear_predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#exercicio\n",
        "data_set = {\n",
        "    'remedio': ['A', 'AB' ,'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'JK','K', 'L', 'M'],\n",
        "    'colateral': ['alto', 'baixo', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio','alto', 'baixo', 'medio'],\n",
        "    'nivel_efetividade_porcentagem': [20, np.nan, 60, 60, 30, 65, 50, 90, 20, 15, 50, np.nan,75, 40, 40],\n",
        "    'passa': ['não', 'sim' ,'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'não', 'não', 'não', 'não', 'sim', 'sim', 'não']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data_set)\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "df['nivel_efetividade_porcentagem'] = imputer.fit_transform(df[['nivel_efetividade_porcentagem']])\n",
        "\n",
        "column_transformer = ColumnTransformer(\n",
        "    [('enconder', OneHotEncoder(), ['remedio', 'colateral'])],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "x = column_transformer.fit_transform(df.drop('passa', axis=1))\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['passa'])\n",
        "\n",
        "logistic_regression =  LogisticRegression()\n",
        "logistic_regression.fit(x, y)\n",
        "\n",
        "#Dados para fazer a previsões\n",
        "\n",
        "predictions_data_set = pd.DataFrame({\n",
        "    'remedio': ['A', 'AB' ,'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'JK','K', 'L', 'M'],\n",
        "    'colateral': ['baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio','alto', 'baixo', 'medio'],\n",
        "    'nivel_efetividade_porcentagem': [30, 50, 60, 30, 40, 55, 60, 70, 30, 25, 30, 60, 30, 50, 60],\n",
        "})\n",
        "\n",
        "transform = column_transformer.transform(predictions_data_set)\n",
        "\n",
        "predict = logistic_regression.predict(transform)\n",
        "transform_predict = label_encoder.inverse_transform(predict)\n",
        "print(transform_predict)\n",
        "\n",
        "predictions_data_set['passa'] = transform_predict\n",
        "print(predictions_data_set)\n"
      ],
      "metadata": {
        "id": "gCOu6MMhLCTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Exercício: Análise de Desempenho de Veículos Elétricos\n",
        "conjunto_de_dados = pd.DataFrame({\n",
        "    'fabricante': ['Tesla', 'BYD', 'Tesla', 'GM', 'Ford', 'BYD', 'Volkswagen', 'Rivian', 'Nissan', 'Hyundai', 'GM', 'Ford', 'Tesla', 'Volkswagen', 'Rivian'],\n",
        "    'tipo_bateria': ['LFP', 'NMC', 'NMC', 'Ultium', 'LFP', 'LFP', 'NMC', 'NMC', 'LFP', 'NMC', 'Ultium', 'LFP', 'NMC', 'LFP', 'NMC'],\n",
        "    'categoria_veiculo': ['sedan', 'SUV', 'SUV', 'pickup', 'SUV', 'sedan', 'hatch', 'SUV', 'hatch', 'SUV', 'pickup', 'SUV', 'sedan', 'hatch', 'pickup'],\n",
        "    'capacidade_bateria_kmh':  [75, 85.5, 100, 200, 98, 72.5, 58, 180, 62, 77.4, 210, 91, 82, 55, 135],\n",
        "    'potencia_motor_cv': [350, 310, 450, 400, 290, 280, 204, 415, 214, 305, 380, 285, 420, 190, 408],\n",
        "    'autonomia_km': [550, 520, 610, 640, 490, 480, 380, 505, 385, 460, 660, 475, 580, 350, 510]\n",
        "})\n",
        "\n",
        "df = conjunto_de_dados\n",
        "\n",
        "column_transform = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(), ['fabricante', 'tipo_bateria']),\n",
        "        ('ordinal', OrdinalEncoder(categories=[['hatch', 'sedan', 'SUV', 'pickup']]), ['categoria_veiculo'])\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "  )\n",
        "\n",
        "x = column_transform.fit_transform(df.drop('autonomia_km', axis=1))\n",
        "y = df['autonomia_km']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "x_pred = regressor.predict(X_test)\n",
        "print(\"Predictions for X_test:\", x_pred)\n",
        "\n",
        "#mean absolute error e r2 score\n",
        "\n",
        "score = mean_absolute_error(y_test, x_pred)\n",
        "print(\"Mean Absolute Error:\", score)\n",
        "r2_score_value = r2_score(y_test, x_pred)\n",
        "print(\"R2 Score:\", r2_score_value)\n",
        "\n",
        "dados_para_previsao = pd.DataFrame({\n",
        "    'fabricante': ['Tesla', 'BYD', 'Ford', 'Hyundai', 'Rivian'],\n",
        "    'tipo_bateria': ['NMC', 'LFP', 'LFP', 'NMC', 'NMC'],\n",
        "    'categoria_veiculo': ['SUV', 'sedan', 'SUV', 'hatch', 'pickup'],\n",
        "    'capacidade_bateria_kmh': [95, 78, 88, 65, 160],\n",
        "    'potencia_motor_cv': [420, 295, 300, 220, 395]\n",
        "})\n",
        "\n",
        "dado_transformado = column_transform.transform(dados_para_previsao)\n",
        "\n",
        "previsao = regressor.predict(dado_transformado)\n",
        "\n",
        "print(\"Previsões: \")\n",
        "print(previsao)\n",
        "\n",
        "dados_para_previsao['autonomia_km'] = previsao\n",
        "print(dados_para_previsao)"
      ],
      "metadata": {
        "id": "No5yRhZjLFIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exercicio de treino\n",
        "data_set = {\n",
        "    'Nomes': ['João', 'Maria', 'Pedro', 'Ana', 'Carlos'],\n",
        "    'Idade': [25, np.nan, 35, 40, np.nan],\n",
        "    'Saúde': ['Saudavel', 'Doente', 'Intermediario', 'Saudavel', 'Doente'],\n",
        "    'Risco': ['Baixo', 'Alto', 'Medio', 'Baixo', 'Alto']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data_set)\n",
        "\n",
        "preprocessador = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]),\n",
        "      [ 'Idade']),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['Nomes', 'Saúde'])\n",
        "])\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessador),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "x = df.drop('Risco', axis=1)\n",
        "y = df['Risco']\n",
        "\n",
        "pipeline.fit(x, y)\n",
        "\n",
        "conjunto_de_dados = {\n",
        "    'Nomes': ['Marta', 'John', 'Fred', 'Ari', 'Justin'],\n",
        "    'Idade': [30, 21, 35, 20, 31],\n",
        "    'Saúde': ['Doente', 'Saudavel', 'Doente', 'Intermediario', 'Saudavel']\n",
        "}\n",
        "\n",
        "novo_conjunto = pd.DataFrame(conjunto_de_dados)\n",
        "predictions = pipeline.predict(novo_conjunto)\n",
        "novo_conjunto['passa'] = predictions\n",
        "print(novo_conjunto)\n",
        "\n"
      ],
      "metadata": {
        "id": "FTPYVZW7LKqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exercicio\n",
        "conjunto_de_dados = {\n",
        "    'remedio': ['A', 'AB' ,'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'JK','K', 'L', 'M'],\n",
        "    'colateral': ['alto', 'baixo', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio','alto', 'baixo', 'medio'],\n",
        "    'nivel_efetividade_porcentagem': [20, np.nan, 60, 60, 30, 65, 50, 90, 20, 15, 50, np.nan,75, 40, 40],\n",
        "    'passa': ['não', 'sim' ,'sim', 'sim', 'não', 'sim', 'sim', 'sim', 'não', 'não', 'não', 'não', 'sim', 'sim', 'não']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(conjunto_de_dados)\n",
        "\n",
        "preprocessamente = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]),\n",
        "     ['nivel_efetividade_porcentagem']),\n",
        "    ('cat', OneHotEncoder(), ['remedio', 'colateral'])\n",
        "])\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessamente),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "x = df.drop('passa', axis=1)\n",
        "y =df['passa']\n",
        "\n",
        "pipeline.fit(x, y)\n",
        "\n",
        "previsoes_dados = pd.DataFrame({\n",
        "    'remedio': ['A', 'AB' ,'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'JK','K', 'L', 'M'],\n",
        "    'colateral': ['baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio', 'baixo', 'alto', 'medio','alto', 'baixo', 'medio'],\n",
        "    'nivel_efetividade_porcentagem': [30, 50, 60, 30, 40, 55, 60, 70, 30, 25, 30, 60, 30, 50, 60],\n",
        "})\n",
        "\n",
        "predictions = pipeline.predict(previsoes_dados)\n",
        "previsoes_dados['passa'] = predictions\n",
        "print(previsoes_dados)\n"
      ],
      "metadata": {
        "id": "yhMOJG5sLLLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date\n",
        "#Exercício: Sistema de Recomendação de Filmes\n",
        "\"\"\"\n",
        "Desafio Opcional\n",
        "1 - Modifique o ColumnTransformer para usar MinMaxScaler em vez de StandardScaler nas features numéricas.\n",
        "\n",
        "2 - Adicione uma feature de \"idade do filme\" (ano atual - ano_lancamento) antes da transformação.\n",
        "\n",
        "3 -Experimente usar um modelo de RandomForestRegressor e compare os resultados.\n",
        "\n",
        "\"\"\"\n",
        "data_set_filmes = pd.DataFrame({\n",
        "    'titulo': ['O Poderoso Chefão', 'Interestelar', 'Parasita', 'Cidade de Deus', 'Matrix', 'Clube da Luta', 'A Origem', 'O Senhor dos Anéis', 'Pulp Fiction', 'Coringa', 'Forrest Gump', 'Gladiador', 'Os Infiltrados', 'Seven', 'De Volta para o Futuro'],\n",
        "    'genero': ['Drama', 'Ficção Científica', 'Thriller', 'Drama', 'Ficção Científica', 'Drama', 'Ficção Científica', 'Fantasia', 'Crime', 'Drama', 'Drama', 'Ação', 'Crime', 'Thriller', 'Ficção Científica'],\n",
        "    'classificacao_etaria': ['18+', '12+', '16+', '18+', '14+', '18+', '14+', '12+', '18+', '16+', '12+', '16+', '16+', '18+', 'Livre'],\n",
        "    'diretor': ['Coppola', 'Nolan', 'Bong', 'Meirelles', 'Wachowski', 'Fincher', 'Nolan', 'Jackson', 'Tarantino', 'Phillips', 'Zemeckis', 'Scott', 'Scorsese', 'Fincher', 'Zemeckis'],\n",
        "    'duracao_minutos': [175, 169, 132, 130, 136, 139, 148, 178, 154, 122, 142, 155, 151, 127, 116],\n",
        "    'orcamento_milhoes': [6, 165, 11, 3, 63, 63, 160, 93, 8, 55, 55, 103, 90, 33, 19],\n",
        "    'ano_lancamento': [1972, 2014, 2019, 2002, 1999, 1999, 2010, 2001, 1994, 2019, 1994, 2000, 2006, 1995, 1985],\n",
        "    'avaliacao_media': [9.2, 8.6, 8.6, 8.6, 8.7, 8.8, 8.8, 8.9, 8.9, 8.4, 8.8, 8.5, 8.5, 8.6, 8.5]\n",
        "})\n",
        "\n",
        "df = data_set_filmes\n",
        "\n",
        "dia_atual = date.today()\n",
        "ano_atual = dia_atual.year\n",
        "\n",
        "df['idade_do_filme'] = ano_atual - df['ano_lancamento']\n",
        "\n",
        "preprocessamento = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('scaler', MinMaxScaler())\n",
        "        ]), ['duracao_minutos', 'orcamento_milhoes', 'ano_lancamento', 'idade_do_filme']),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), ['genero', 'diretor']),\n",
        "        ('ordinal', OrdinalEncoder(categories=[['Livre', '12+', '14+', '16+', '18+']]), ['classificacao_etaria'] )\n",
        "    ], remainder = 'passthrough'\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessamento),\n",
        "    ('classifier', LinearRegression())\n",
        "])\n",
        "\n",
        "pipeline2 = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessamento),\n",
        "    ('classifier', RandomForestRegressor(max_depth=2, random_state=0))\n",
        "])\n",
        "\n",
        "\n",
        "x = df.drop(['avaliacao_media', 'titulo'], axis=1)\n",
        "y = df['avaliacao_media']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "pipeline2.fit(X_train, y_train)\n",
        "\n",
        "print(\"Pipeline com LinearRegression\")\n",
        "\n",
        "x_pred1 = pipeline.predict(X_test)\n",
        "print(\"Predictions for X_test:\", x_pred1)\n",
        "\n",
        "print(\"Pipeline com RandomForestRegressor\")\n",
        "\n",
        "x_pred2 = pipeline2.predict(X_test)\n",
        "print(\"Predictions for X_test:\", x_pred2)\n",
        "\n",
        "score = mean_squared_error(y_test, x_pred)\n",
        "print(\"Mean Squared Error:\", score)\n",
        "\n",
        "r2_score_value = r2_score(y_test, x_pred)\n",
        "print(\"R2 Score:\", r2_score_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "novos_filmes = pd.DataFrame({\n",
        "    'titulo': ['Duna', '1917', 'O Irlandês'],\n",
        "    'genero': ['Ficção Científica', 'Drama', 'Crime'],\n",
        "    'classificacao_etaria': ['14+', '16+', '18+'],\n",
        "    'diretor': ['Villeneuve', 'Mendes', 'Scorsese'],\n",
        "    'duracao_minutos': [155, 119, 209],\n",
        "    'orcamento_milhoes': [165, 95, 159],\n",
        "    'ano_lancamento': [2021, 2019, 2019]\n",
        "})\n",
        "\n",
        "# Calculate 'idade_do_filme' for the new data as well\n",
        "novos_filmes['idade_do_filme'] = ano_atual - novos_filmes['ano_lancamento']\n",
        "\n",
        "predicoesPipeline = pipeline.predict(novos_filmes)\n",
        "predicoesPipeline2 = pipeline2.predict(novos_filmes)\n",
        "\n",
        "print(\"\\nPipeline com LinearRegression\")\n",
        "print(predicoesPipeline, end='\\n\\n')\n",
        "\n",
        "print(\"Pipeline com RandomForestRegressor\")\n",
        "print(predicoesPipeline2, end='\\n\\n')\n",
        "\n",
        "#LR == Linear Regression RFR == Random Forest Regressor\n",
        "novos_filmes['avaliacao_media_LR'] = predicoesPipeline\n",
        "novos_filmes['avaliacao_media_RFR'] = predicoesPipeline2\n",
        "\n",
        "print(novos_filmes)"
      ],
      "metadata": {
        "id": "ZQ6cXm93LQkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}